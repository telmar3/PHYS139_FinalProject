{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483bbf51",
   "metadata": {},
   "source": [
    "# Pre-Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42acc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16781312, 21)\n",
      "(16781312,)\n"
     ]
    }
   ],
   "source": [
    "#Given pseudocode to grab the .h5 data file\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"/home/ljian/private/PHYS 139 Final Project/deepclean-1251335314-4097.h5\", \"r\") as f:\n",
    "    X = []\n",
    "    for channel, timeseries in f.items():\n",
    "        if channel == \"H1:GDS-CALIB_STRAIN\":\n",
    "            y = timeseries[:]\n",
    "        else:\n",
    "            X.append(timeseries[:])\n",
    "X = np.stack(X, axis=-1) # this will do channels last (as is typically done for Keras)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433ee1f",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then to construct inputs/outputs, you just\n",
    "# slice windows from these two timeseries\n",
    "\n",
    "# window_size = 8192 to replicate data size for paper\n",
    "# Can change this around to try different shapes\n",
    "window_length = 2\n",
    "sample_rate = 4096\n",
    "window_size = window_length * sample_rate\n",
    "\n",
    "# sample a batch of random windows\n",
    "# Dr. Duarte suggests making a LOT\n",
    "# Like 10k\n",
    "# If we want less, standard is 32\n",
    "batch_size = 1000\n",
    "X_batch, y_batch = [], []\n",
    "for i in range(batch_size):\n",
    "    idx = np.random.randint(X.shape[0] - window_size)\n",
    "    X_batch.append(X[idx: idx + window_size])\n",
    "    y_batch.append(y[idx: idx + window_size])\n",
    "    \n",
    "#can do the above process as many times as you want\n",
    "#maybe change batchsize to 10000\n",
    "#increasing batch_size increases chances to see overlap, \n",
    "#different data in different areas of the dataset \n",
    "\n",
    "X_batch = np.stack(X_batch)\n",
    "y_batch = np.stack(y_batch)\n",
    "\n",
    "print(X_batch.shape)\n",
    "print(y_batch.shape)\n",
    "\n",
    "plt.plot(y[0:100])\n",
    "plt.title(\"Strain Data\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X_batch[0][:,0])\n",
    "plt.title(\"First Aux Channel. First Batch\")\n",
    "plt.show()\n",
    "\n",
    "strain_data = y_batch\n",
    "witness_data = X_batch\n",
    "channels = 21\n",
    "\n",
    "#may be the wrong size\n",
    "#Ask author what size to train model on, sample more finely doesnt have to be most 32k, try (8192, 21) slices; would\n",
    "#likely be 2s of data.\n",
    "#possibly increase batch size\n",
    "#have to train_test_split earlier, before bringing into cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fe4ac",
   "metadata": {},
   "source": [
    "## Pre-processing data structure:\n",
    "\n",
    "1. 8th Order Butterworth: Aliasing filter to mitigate power from outside the witnessed noise frequencies;\n",
    "\n",
    "2. StandardScalar: Unit variance, Zero mean;\n",
    "\n",
    "3. Windowing: Divide data into smaller overlapping windows;\n",
    " * Segment Length: 8.00 Seconds;\n",
    " * 0.5 Hz => DFT of 2 Seconds;\n",
    "    \n",
    "4. Welches Method: 1 Second DFT overlap;\n",
    "\n",
    "5. Training: Segment overlap [%] = 96.875\n",
    "\n",
    "6. Testing: Segment overlap [%] = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b718d62",
   "metadata": {},
   "source": [
    "## PSD and CSD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0: Butterworth\n",
    "print(\"Finding pass-band frequencies via Cross Spectral Density Analysis\")\n",
    "# Find band pass values per channel\n",
    "\n",
    "for i in range(0,21):\n",
    "    plt.csd(X[:,i], y, Fs = 4096)\n",
    "    plt.title(\"CSD over Channel i and Strain\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Finding pass-band frequencies via Cross Spectral Density Analysis\")\n",
    "## Find band pass values per channel\n",
    "for i in range(0,21):\n",
    "    plt.psd(X[:,i], Fs = 4096)\n",
    "    plt.title(\"PSD over all Channels\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b740ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Butterworth Filter\")\n",
    "N = 8 # order of butterworth filter\n",
    "\n",
    "Wn = [0, 0.3] # Band-pass [low end, high end]\n",
    "# Wn = [10, 100] # Band-pass [low end, high end]\n",
    "\n",
    "filter_type = \"bp\"\n",
    "fs = Wn[1]/2\n",
    "\n",
    "b, a = signal.butter(N, Wn, filter_type, analog=True)\n",
    "w, h = signal.freqs(b, a)\n",
    "plt.semilogx(w, 20 * np.log10(abs(h)))\n",
    "plt.title('Butterworth filter frequency response')\n",
    "plt.xlabel('Frequency [radians / second]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.margins(0, 0.1)\n",
    "plt.grid(which='both', axis='both')\n",
    "plt.axvline(100, color='green') # cutoff frequency\n",
    "plt.show()\n",
    "butter_sos = signal.butter(N, Wn, filter_type, fs , output = 'sos')\n",
    "print(\"Butterworth filter built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a58b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Apply butter_sos to data\n",
    "print(\"Applying Butterworth to data\")\n",
    "print(witness_data.shape)\n",
    "plt.plot(witness_data[0][:,0])\n",
    "plt.show()\n",
    "for idx in range(len(witness_data)):\n",
    "    for channel in range(channels):\n",
    "        witness_data[idx][:, channel] = signal.sosfilt(butter_sos, witness_data[idx][:, channel])\n",
    "plt.plot(witness_data[0][:,0])\n",
    "plt.show()\n",
    "print(\"Butterworth filter applied to data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec7a27",
   "metadata": {},
   "source": [
    "## 3: Standard Scalar (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944374c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Normalization in progress\")\n",
    "\n",
    "plt.plot(witness_data[0][:,0])\n",
    "plt.show()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "strain_data = np.reshape(strain_data, (-1,1))\n",
    "\n",
    "## For Post Processing\n",
    "strain_mean = np.mean(strain_data)\n",
    "strain_std = np.std(strain_data)\n",
    "\n",
    "\n",
    "scaler.fit(strain_data)\n",
    "strain_data = scaler.transform(strain_data)\n",
    "\n",
    "\n",
    "test_1 = scaler.transform(np.reshape(witness_data[1][:,0], (-1,1)))\n",
    "plt.plot(test_1, label = \"Z_score\")\n",
    "plt.plot(witness_data[0][:,0], label = \"OG Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"CNN Data Ready, Import witness_data\")\n",
    "print(witness_data.shape)\n",
    "\n",
    "# for idx in range(len(witness_data)):\n",
    "#     for channel in range(channels):\n",
    "#         reshaped_witness_data = np.reshape(witness_data[idx][:, channel], (-1,1))\n",
    "#         reshaped_witness_data = scaler.transform(reshaped_witness_data)\n",
    "# print(witness_data.shape)\n",
    "\n",
    "\n",
    "print(\"Normalization Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300407",
   "metadata": {},
   "source": [
    "## 4: Windowing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f62932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Windowing\n",
    "# Should match window_length from Batching cell\n",
    "window_length = 2\n",
    "DFT_length = 2\n",
    "sample_rate = 4096\n",
    "window_size = window_length * sample_rate\n",
    "DFT_size = DFT_length * sample_rate\n",
    "overlap_percent = 0.96875\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa30920",
   "metadata": {},
   "source": [
    "## 5: Welch's Method and DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Welches Method\n",
    "print(\"Applying Welch's Method\")\n",
    "window_type = 'hann'\n",
    "nperseg_train = window_size\n",
    "noverlap_train = window_size*(1-overlap_percent)\n",
    "nfft = DFT_size\n",
    "new_data = []\n",
    "\n",
    "for batch in range(len(witness_data)):\n",
    "    batch_data = []\n",
    "    for channel in range(channels):\n",
    "        welch_data = signal.welch(witness_data[batch][:, channel], sample_rate, window = 'hann')\n",
    "        batch_data.append(welch_data[1])\n",
    "    batch_data = np.stack(batch_data, axis = -1)\n",
    "    new_data.append(batch_data)\n",
    "new_data = np.stack(new_data, axis = 0)\n",
    "\n",
    "print(\"Welch's Method Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fbc79",
   "metadata": {},
   "source": [
    "## API Call to send data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_freq_data():\n",
    "    \"\"\"\n",
    "    new_data == Spectral density data data,\n",
    "    strain_data == GW processed data\n",
    "    \n",
    "    Used for loss function computaiton\n",
    "    \"\"\"\n",
    "    return witness_data, strain_data\n",
    "\n",
    "def send_time_data():\n",
    "    \"\"\"\n",
    "    witness_data == filtered, and z_scored aux channel data,\n",
    "    strain_data == GW processed data\n",
    "    \n",
    "    Used for CNN training. Not split yet.\n",
    "    \"\"\"\n",
    "    return witness_data, strain_data\n",
    "\n",
    "\n",
    "def send_post_processing_params():\n",
    "    \"\"\"\n",
    "    strain_mean == mean of data used for z-score\n",
    "    strain_std = std dev used for z-score\n",
    "    \n",
    "    Will be needed in post processing. Call function to return the old mean and std dev to reverse z-score\n",
    "    \"\"\"\n",
    "    return strain_mean, strain_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
