{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483bbf51",
   "metadata": {},
   "source": [
    "# Pre-Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42acc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16781312, 21)\n",
      "(16781312,)\n"
     ]
    }
   ],
   "source": [
    "#Given pseudocode to grab the .h5 data file\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"/home/ljian/private/PHYS 139 Final Project/deepclean-1251335314-4097.h5\", \"r\") as f:\n",
    "    X = []\n",
    "    for channel, timeseries in f.items():\n",
    "        if channel == \"H1:GDS-CALIB_STRAIN\":\n",
    "            y = timeseries[:]\n",
    "        else:\n",
    "            X.append(timeseries[:])\n",
    "X = np.stack(X, axis=-1) # this will do channels last (as is typically done for Keras)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15848031",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_index = int(X.shape[0] * 4 / 5)\n",
    "\n",
    "X_train = X[:train_max_index]\n",
    "y_train = y[:train_max_index]\n",
    "\n",
    "X_test = X[train_max_index:]\n",
    "y_test = y[train_max_index:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433ee1f",
   "metadata": {},
   "source": [
    "## Batching (Train and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then to construct inputs/outputs, you just\n",
    "# slice windows from these two timeseries\n",
    "\n",
    "# window_size = 8192 to replicate data size for paper\n",
    "# Can change this around to try different shapes\n",
    "window_length = 2 # s\n",
    "sample_rate = 4096 # Hz\n",
    "window_size = window_length * sample_rate\n",
    "\n",
    "# train_batches in your code is currently 1000, which is fine, \n",
    "# but i set it here to int(total time steps / window size).\n",
    "\n",
    "\n",
    "# Train data batching\n",
    "train_batches = int(X_train.shape[0]/window_size) \n",
    "X_train_batch, y_train_batch = [], []\n",
    "for i in range(train_batches):\n",
    "    idx = np.random.randint(X_train.shape[0] - window_size)\n",
    "    X_train_batch.append(X_train[idx: idx + window_size])\n",
    "    y_train_batch.append(y_train[idx: idx + window_size])\n",
    "\n",
    "X_train_batch = np.stack(X_train_batch)\n",
    "y_train_batch = np.stack(y_train_batch)\n",
    "\n",
    "print(X_train_batch.shape)\n",
    "print(y_train_batch.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Test data batching\n",
    "# the idea here is the test data should be fixed and not randomized/shuffled\n",
    "# so we're just going to grab as many contiguous slices of it as we can\n",
    "test_batches = int(X_test.shape[0]/window_size)\n",
    "X_test_batch, y_test_batch = [], []\n",
    "for i in range(test_batches):\n",
    "    idx = i * window_size\n",
    "    X_test_batch.append(X_test[idx: idx + window_size])\n",
    "    y_test_batch.append(y_test[idx: idx + window_size])\n",
    "\n",
    "X_test_batch = np.stack(X_test_batch)\n",
    "y_test_batch = np.stack(y_test_batch)\n",
    "\n",
    "print(X_test_batch.shape)\n",
    "print(y_test_batch.shape)\n",
    "\n",
    "\n",
    "plt.plot(y_train_batch[0:100])\n",
    "plt.title(\"Strain Data\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X_train_batch[0][:,0])\n",
    "plt.title(\"First Aux Channel. First Batch\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Train Data\n",
    "strain_data_train = y_train_batch\n",
    "witness_data_train = X_train_batch\n",
    "\n",
    "# Test Dats\n",
    "strain_data_test = y_test_batch\n",
    "witness_data_test = X_test_batch\n",
    "\n",
    "channels = 21\n",
    "\n",
    "#may be the wrong size\n",
    "#Ask author what size to train model on, sample more finely doesnt have to be most 32k, try (8192, 21) slices; would\n",
    "#likely be 2s of data.\n",
    "#possibly increase batch size\n",
    "#have to train_test_split earlier, before bringing into cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fe4ac",
   "metadata": {},
   "source": [
    "## Pre-processing data structure:\n",
    "\n",
    "1. 8th Order Butterworth: Aliasing filter to mitigate power from outside the witnessed noise frequencies;\n",
    "\n",
    "2. StandardScalar: Unit variance, Zero mean;\n",
    "\n",
    "3. Windowing: Divide data into smaller overlapping windows;\n",
    " * Segment Length: 8.00 Seconds;\n",
    " * 0.5 Hz => DFT of 2 Seconds;\n",
    "    \n",
    "4. Welches Method: 1 Second DFT overlap;\n",
    "\n",
    "5. Training: Segment overlap [%] = 96.875\n",
    "\n",
    "6. Testing: Segment overlap [%] = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b718d62",
   "metadata": {},
   "source": [
    "## PSD and CSD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0: Butterworth\n",
    "print(\"Finding pass-band frequencies via Cross Spectral Density Analysis\")\n",
    "# Find band pass values per channel\n",
    "\n",
    "for i in range(0,21):\n",
    "    plt.csd(X[:,i], y, Fs = 4096)\n",
    "    plt.title(\"CSD over Channel i and Strain\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Finding pass-band frequencies via Cross Spectral Density Analysis\")\n",
    "## Find band pass values per channel\n",
    "for i in range(0,21):\n",
    "    plt.psd(X[:,i], Fs = 4096)\n",
    "    plt.title(\"PSD over all Channels\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b740ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Butterworth Filter\")\n",
    "N = 8 # order of butterworth filter\n",
    "\n",
    "Wn = [0, 0.3] # Band-pass [low end, high end]\n",
    "# Wn = [10, 100] # Band-pass [low end, high end]\n",
    "\n",
    "filter_type = \"bp\"\n",
    "fs = Wn[1]/2\n",
    "\n",
    "b, a = signal.butter(N, Wn, filter_type, analog=True)\n",
    "w, h = signal.freqs(b, a)\n",
    "plt.semilogx(w, 20 * np.log10(abs(h)))\n",
    "plt.title('Butterworth filter frequency response')\n",
    "plt.xlabel('Frequency [radians / second]')\n",
    "plt.ylabel('Amplitude [dB]')\n",
    "plt.margins(0, 0.1)\n",
    "plt.grid(which='both', axis='both')\n",
    "plt.axvline(100, color='green') # cutoff frequency\n",
    "plt.show()\n",
    "butter_sos = signal.butter(N, Wn, filter_type, fs , output = 'sos')\n",
    "print(\"Butterworth filter built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a58b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Apply butter_sos to data\n",
    "print(\"Applying Butterworth to data\")\n",
    "print(\"Train Witness shape:\", witness_data_train.shape)\n",
    "print(\"test Witness shape:\", witness_data_test.shape)\n",
    "\n",
    "# Pre-filtered plot\n",
    "plt.plot(witness_data[0][:,0])\n",
    "plt.show()\n",
    "\n",
    "# Filter Train Data\n",
    "for idx in range(len(witness_data_train)):\n",
    "    for channel in range(channels):\n",
    "        witness_data_train[idx][:, channel] = signal.sosfilt(butter_sos, witness_data_train[idx][:, channel])\n",
    "\n",
    "# Filter Test Data\n",
    "for idx in range(len(witness_data_test)):\n",
    "    for channel in range(channels):\n",
    "        witness_data_test[idx][:, channel] = signal.sosfilt(butter_sos, witness_data_test[idx][:, channel])        \n",
    "        \n",
    "# Post-filtered plot        \n",
    "plt.plot(witness_data_train[0][:,0])\n",
    "plt.show()\n",
    "print(\"Butterworth filter applied to data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec7a27",
   "metadata": {},
   "source": [
    "## 3: Standard Scalar (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944374c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Normalization in progress\")\n",
    "\n",
    "# Train Data\n",
    "plt.plot(witness_data_train[0][:,0])\n",
    "plt.show()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "strain_data_train = np.reshape(strain_data_train, (-1,1))\n",
    "\n",
    "## For Post Processing\n",
    "strain_mean_train = np.mean(strain_data_train)\n",
    "strain_std_train = np.std(strain_data_train)\n",
    "\n",
    "\n",
    "scaler.fit(strain_data_train)\n",
    "strain_data_train = scaler.transform(strain_data_train)\n",
    "\n",
    "\n",
    "test_1 = scaler.transform(np.reshape(witness_data_train[1][:,0], (-1,1)))\n",
    "plt.plot(test_1, label = \"Z_score\")\n",
    "plt.plot(witness_data_train[0][:,0], label = \"OG Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test Data\n",
    "plt.plot(witness_data_test[0][:,0])\n",
    "plt.show()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "strain_data_test = np.reshape(strain_data_test, (-1,1))\n",
    "\n",
    "## For Post Processing\n",
    "strain_mean_test = np.mean(strain_data_test)\n",
    "strain_std_test = np.std(strain_data_test)\n",
    "\n",
    "\n",
    "scaler.fit(strain_data_test)\n",
    "strain_data_test = scaler.transform(strain_data_test)\n",
    "\n",
    "\n",
    "test_1 = scaler.transform(np.reshape(witness_data_test[1][:,0], (-1,1)))\n",
    "plt.plot(test_1, label = \"Z_score\")\n",
    "plt.plot(witness_data_test[0][:,0], label = \"OG Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"CNN Data Ready, Import witness_data\")\n",
    "print(witness_data_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Normalization Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300407",
   "metadata": {},
   "source": [
    "## 4: Windowing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f62932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Windowing\n",
    "# Should match window_length from Batching cell\n",
    "window_length = 2\n",
    "DFT_length = 2\n",
    "sample_rate = 4096\n",
    "window_size = window_length * sample_rate\n",
    "DFT_size = DFT_length * sample_rate\n",
    "overlap_percent = 0.96875\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa30920",
   "metadata": {},
   "source": [
    "## 5: Welch's Method and DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Welches Method\n",
    "print(\"Applying Welch's Method\")\n",
    "window_type = 'hann'\n",
    "nperseg_train = window_size\n",
    "noverlap_train = window_size*(1-overlap_percent)\n",
    "nfft = DFT_size\n",
    "freq_data_train = []\n",
    "freq_data_test = []\n",
    "\n",
    "# Train Data\n",
    "for batch in range(len(witness_data_train)):\n",
    "    batch_data = []\n",
    "    for channel in range(channels):\n",
    "        welch_data = signal.welch(witness_data_train[batch][:, channel], sample_rate, window = 'hann')\n",
    "        batch_data.append(welch_data[1])\n",
    "    batch_data = np.stack(batch_data, axis = -1)\n",
    "    freq_data_train.append(batch_data)\n",
    "freq_data_train = np.stack(freq_data, axis = 0)\n",
    "\n",
    "# Test data\n",
    "for batch in range(len(witness_data_test)):\n",
    "    batch_data = []\n",
    "    for channel in range(channels):\n",
    "        welch_data = signal.welch(witness_data_test[batch][:, channel], sample_rate, window = 'hann')\n",
    "        batch_data.append(welch_data[1])\n",
    "    batch_data = np.stack(batch_data, axis = -1)\n",
    "    freq_data_test.append(batch_data)\n",
    "freq_data_test = np.stack(freq_data, axis = 0)\n",
    "\n",
    "print(\"Welch's Method Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fbc79",
   "metadata": {},
   "source": [
    "## API Call to send data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_freq_data():\n",
    "    \"\"\"\n",
    "    new_data == Spectral density data data,\n",
    "    strain_data == GW processed data\n",
    "    \n",
    "    Used for loss function computaiton\n",
    "    \"\"\"\n",
    "    return freq_data_train, strain_data_train, freq_data_test, strain_data_test\n",
    "\n",
    "def send_time_data():\n",
    "    \"\"\"\n",
    "    Train Data: \n",
    "    witness_data_train == filtered, and z_scored aux channel data,\n",
    "    strain_data_train == GW processed data\n",
    "    \n",
    "    Test Data: \n",
    "    witness_data_test == filtered, and z_scored aux channel data,\n",
    "    strain_data_test == GW processed data\n",
    "    \n",
    "    Used for CNN training. Not split yet.\n",
    "    \"\"\"\n",
    "    return witness_data_train, strain_data_train, witness_data_test, strain_data_test\n",
    "\n",
    "\n",
    "def send_post_processing_params():\n",
    "    \"\"\"\n",
    "    Train Data\n",
    "    strain_mean_train == mean of data used for z-score\n",
    "    strain_std_train = std dev used for z-score\n",
    "    \n",
    "    Test Data\n",
    "    strain_mean_test == mean of data used for z-score\n",
    "    strain_std_test = std dev used for z-score\n",
    "    \n",
    "    Will be needed in post processing. Call function to return the old mean and std dev to reverse z-score\n",
    "    \"\"\"\n",
    "    return strain_mean_train, strain_std_train, strain_mean_test, strain_std_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
