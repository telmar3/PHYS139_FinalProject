import numpy as np
import h5py

with h5py.File("/path/to/file.h5", "r") as f:
    X = []
    for channel, timeseries in f.items():
        if channel = "H1:GDS-CALIB_STRAIN":
            y = timeseries
        else:
            X.append(timeseries)
X = np.stack(X)

# then to construct inputs/outputs, you just
# slice windows from these two timeseries
window_length = 8
sample_rate = 4096
window_size = window_length * sample_rate

# sample a batch of random windows
batch_size = 32
X_batch, y_batch = []
for i in range(batch_size):
    idx = np.random.randint(X.shape[-1] - window_size)
    X_batch.append(X[:, idx: idx + window_size])
    y_batch.append(y[idx: idx + window_size])

X_batch = np.stack(X_batch)
y_batch = np.stack(y_batch)

# this method of generating batches is likely
# to be very CPU-bound, and won't be any good
# in any real training scenario. Luckily if you're
# using torch and you can
# pip install ml4gw
# we've built a set of utilities for making
# iterating through timeseries data easier
from ml4gw.dataloading import InMemoryDataset
dataloader = InMemoryDataset(
    X=X,
    y=y,
    kernel_size=window_size,
    batch_size=batch_size,
    coincident=True,
    shuffle=True
    device="cuda"
)

num_epochs = 100
for i in range(num_epochs):
    for X, y in dataloader:
        do_some_training(X, y)
